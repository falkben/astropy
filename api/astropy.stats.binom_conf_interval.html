


<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>binom_conf_interval &#8212; Astropy v5.2.dev96+g04a0cf8bb</title>
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/bootstrap-astropy.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../_static/sidebar.js"></script>
    <script type="text/javascript" src="../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../_static/astropy_logo.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="binned_binom_proportion" href="astropy.stats.binned_binom_proportion.html" />
    <link rel="prev" title="Ripley’s K Function Estimators" href="../stats/ripley.html" />
  
  <meta name="robots" content="noindex, nofollow">
  
  
    <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,600' rel='stylesheet' type='text/css'/>


  </head><body>
<div class="topbar">
  <a class="brand" title="Documentation Home" href="../index.html"><span id="logotext1">astro</span><span id="logotext2">py</span><span id="logotext3">:docs</span></a>
  <ul>
    
    <li><a class="homelink" title="Astropy Homepage" href="http://www.astropy.org"></a></li>
    <li><a title="General Index" href="../genindex.html">Index</a></li>
    <li><a title="Module Index" href="../py-modindex.html">Modules</a></li>
    <li>
      
      
<form action="../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
      
    </li>
  </ul>
</div>

<div class="related">
    <h3>Navigation</h3>
    <ul>
      <li class="right">
	<a href="astropy.stats.binned_binom_proportion.html" title="binned_binom_proportion">
	  next &raquo;
	</a>
      </li>
      <li class="right">
	<a href="../stats/ripley.html" title="Ripley’s K Function Estimators">
	  &laquo; previous
	</a>
	 |
      </li>
      <li>
	<a href="../index.html">Astropy v5.2.dev96+g04a0cf8bb</a>
	 &#187;
      </li>
      <li><a href="../stats/index.html" accesskey="U">Astrostatistics Tools (<code class="xref py py-obj docutils literal notranslate"><span class="pre">astropy.stats</span></code>)</a> &#187;</li>
      
      <li>binom_conf_interval</li> 
    </ul>
</div>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="binom-conf-interval">
<h1>binom_conf_interval<a class="headerlink" href="#binom-conf-interval" title="Permalink to this headline">¶</a></h1>
<dl class="py function">
<dt id="astropy.stats.binom_conf_interval">
<code class="sig-prename descclassname"><span class="pre">astropy.stats.</span></code><code class="sig-name descname"><span class="pre">binom_conf_interval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">k</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confidence_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.68269</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'wilson'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/astropy/stats/funcs.html#binom_conf_interval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#astropy.stats.binom_conf_interval" title="Permalink to this definition">¶</a></dt>
<dd><p>Binomial proportion confidence interval given k successes,
n trials.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>k</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><code class="docutils literal notranslate"><span class="pre">int</span></code></a> or <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a></span></dt><dd><p>Number of successes (0 &lt;= <code class="docutils literal notranslate"><span class="pre">k</span></code> &lt;= <code class="docutils literal notranslate"><span class="pre">n</span></code>).</p>
</dd>
<dt><strong>n</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><code class="docutils literal notranslate"><span class="pre">int</span></code></a> or <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a></span></dt><dd><p>Number of trials (<code class="docutils literal notranslate"><span class="pre">n</span></code> &gt; 0).  If both <code class="docutils literal notranslate"><span class="pre">k</span></code> and <code class="docutils literal notranslate"><span class="pre">n</span></code> are arrays,
they must have the same shape.</p>
</dd>
<dt><strong>confidence_level</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><code class="docutils literal notranslate"><span class="pre">float</span></code></a>, optional</span></dt><dd><p>Desired probability content of interval. Default is 0.68269,
corresponding to 1 sigma in a 1-dimensional Gaussian distribution.
Confidence level must be in range [0, 1].</p>
</dd>
<dt><strong>interval</strong><span class="classifier">{‘wilson’, ‘jeffreys’, ‘flat’, ‘wald’}, optional</span></dt><dd><p>Formula used for confidence interval. See notes for details.  The
<code class="docutils literal notranslate"><span class="pre">'wilson'</span></code> and <code class="docutils literal notranslate"><span class="pre">'jeffreys'</span></code> intervals generally give similar
results, while ‘flat’ is somewhat different, especially for small
values of <code class="docutils literal notranslate"><span class="pre">n</span></code>.  <code class="docutils literal notranslate"><span class="pre">'wilson'</span></code> should be somewhat faster than
<code class="docutils literal notranslate"><span class="pre">'flat'</span></code> or <code class="docutils literal notranslate"><span class="pre">'jeffreys'</span></code>.  The ‘wald’ interval is generally not
recommended.  It is provided for comparison purposes.  Default is
<code class="docutils literal notranslate"><span class="pre">'wilson'</span></code>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl>
<dt><strong>conf_interval</strong><span class="classifier"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ndarray</span></code></a></span></dt><dd><p><code class="docutils literal notranslate"><span class="pre">conf_interval[0]</span></code> and <code class="docutils literal notranslate"><span class="pre">conf_interval[1]</span></code> correspond to the lower
and upper limits, respectively, for each element in <code class="docutils literal notranslate"><span class="pre">k</span></code>, <code class="docutils literal notranslate"><span class="pre">n</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>In situations where a probability of success is not known, it can
be estimated from a number of trials (n) and number of
observed successes (k). For example, this is done in Monte
Carlo experiments designed to estimate a detection efficiency. It
is simple to take the sample proportion of successes (k/n)
as a reasonable best estimate of the true probability
<span class="math notranslate nohighlight">\(\epsilon\)</span>. However, deriving an accurate confidence
interval on <span class="math notranslate nohighlight">\(\epsilon\)</span> is non-trivial. There are several
formulas for this interval (see <a class="reference internal" href="#r7bdc16f6fab4-1" id="id1">[1]</a>). Four intervals are implemented
here:</p>
<p><strong>1. The Wilson Interval.</strong> This interval, attributed to Wilson <a class="reference internal" href="#r7bdc16f6fab4-2" id="id2">[2]</a>,
is given by</p>
<div class="math notranslate nohighlight">
\[CI_{\rm Wilson} = \frac{k + \kappa^2/2}{n + \kappa^2}
\pm \frac{\kappa n^{1/2}}{n + \kappa^2}
((\hat{\epsilon}(1 - \hat{\epsilon}) + \kappa^2/(4n))^{1/2}\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{\epsilon} = k / n\)</span> and <span class="math notranslate nohighlight">\(\kappa\)</span> is the
number of standard deviations corresponding to the desired
confidence interval for a <em>normal</em> distribution (for example,
1.0 for a confidence interval of 68.269%). For a
confidence interval of 100(1 - <span class="math notranslate nohighlight">\(\alpha\)</span>)%,</p>
<div class="math notranslate nohighlight">
\[\kappa = \Phi^{-1}(1-\alpha/2) = \sqrt{2}{\rm erf}^{-1}(1-\alpha).\]</div>
<p><strong>2. The Jeffreys Interval.</strong> This interval is derived by applying
Bayes’ theorem to the binomial distribution with the
noninformative Jeffreys prior <a class="reference internal" href="#r7bdc16f6fab4-3" id="id3">[3]</a>, <a class="reference internal" href="#r7bdc16f6fab4-4" id="id4">[4]</a>. The noninformative Jeffreys
prior is the Beta distribution, Beta(1/2, 1/2), which has the density
function</p>
<div class="math notranslate nohighlight">
\[f(\epsilon) = \pi^{-1} \epsilon^{-1/2}(1-\epsilon)^{-1/2}.\]</div>
<p>The justification for this prior is that it is invariant under
reparameterizations of the binomial proportion.
The posterior density function is also a Beta distribution: Beta(k
+ 1/2, n - k + 1/2). The interval is then chosen so that it is
<em>equal-tailed</em>: Each tail (outside the interval) contains
<span class="math notranslate nohighlight">\(\alpha\)</span>/2 of the posterior probability, and the interval
itself contains 1 - <span class="math notranslate nohighlight">\(\alpha\)</span>. This interval must be
calculated numerically. Additionally, when k = 0 the lower limit
is set to 0 and when k = n the upper limit is set to 1, so that in
these cases, there is only one tail containing <span class="math notranslate nohighlight">\(\alpha\)</span>/2
and the interval itself contains 1 - <span class="math notranslate nohighlight">\(\alpha\)</span>/2 rather than
the nominal 1 - <span class="math notranslate nohighlight">\(\alpha\)</span>.</p>
<p><strong>3. A Flat prior.</strong> This is similar to the Jeffreys interval,
but uses a flat (uniform) prior on the binomial proportion
over the range 0 to 1 rather than the reparametrization-invariant
Jeffreys prior.  The posterior density function is a Beta distribution:
Beta(k + 1, n - k + 1).  The same comments about the nature of the
interval (equal-tailed, etc.) also apply to this option.</p>
<p><strong>4. The Wald Interval.</strong> This interval is given by</p>
<div class="math notranslate nohighlight">
\[CI_{\rm Wald} = \hat{\epsilon} \pm
\kappa \sqrt{\frac{\hat{\epsilon}(1-\hat{\epsilon})}{n}}\]</div>
<p>The Wald interval gives acceptable results in some limiting
cases. Particularly, when n is very large, and the true proportion
<span class="math notranslate nohighlight">\(\epsilon\)</span> is not “too close” to 0 or 1. However, as the
later is not verifiable when trying to estimate <span class="math notranslate nohighlight">\(\epsilon\)</span>,
this is not very helpful. Its use is not recommended, but it is
provided here for comparison purposes due to its prevalence in
everyday practical statistics.</p>
<p>This function requires <code class="docutils literal notranslate"><span class="pre">scipy</span></code> for all interval types.</p>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r7bdc16f6fab4-1"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Brown, Lawrence D.; Cai, T. Tony; DasGupta, Anirban (2001).
“Interval Estimation for a Binomial Proportion”. Statistical
Science 16 (2): 101-133. doi:10.1214/ss/1009213286</p>
</dd>
<dt class="label" id="r7bdc16f6fab4-2"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p>Wilson, E. B. (1927). “Probable inference, the law of
succession, and statistical inference”. Journal of the American
Statistical Association 22: 209-212.</p>
</dd>
<dt class="label" id="r7bdc16f6fab4-3"><span class="brackets"><a class="fn-backref" href="#id3">3</a></span></dt>
<dd><p>Jeffreys, Harold (1946). “An Invariant Form for the Prior
Probability in Estimation Problems”. Proc. R. Soc. Lond.. A 24 186
(1007): 453-461. doi:10.1098/rspa.1946.0056</p>
</dd>
<dt class="label" id="r7bdc16f6fab4-4"><span class="brackets"><a class="fn-backref" href="#id4">4</a></span></dt>
<dd><p>Jeffreys, Harold (1998). Theory of Probability. Oxford
University Press, 3rd edition. ISBN 978-0198503682</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Integer inputs return an array with shape (2,):</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">binom_conf_interval</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="s1">&#39;wilson&#39;</span><span class="p">)</span>  
<span class="go">array([0.57921724, 0.92078259])</span>
</pre></div>
</div>
<p>Arrays of arbitrary dimension are supported. The Wilson and Jeffreys
intervals give similar results, even for small k, n:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">binom_conf_interval</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="mi">5</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="s1">&#39;wilson&#39;</span><span class="p">)</span>  
<span class="go">array([[0.07921741, 0.21597328],</span>
<span class="go">       [0.42078276, 0.61736012]])</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">binom_conf_interval</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,],</span> <span class="mi">5</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="s1">&#39;jeffreys&#39;</span><span class="p">)</span>  
<span class="go">array([[0.0842525 , 0.21789949],</span>
<span class="go">       [0.42218001, 0.61753691]])</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">binom_conf_interval</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="mi">5</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="s1">&#39;flat&#39;</span><span class="p">)</span>  
<span class="go">array([[0.12139799, 0.24309021],</span>
<span class="go">       [0.45401727, 0.61535699]])</span>
</pre></div>
</div>
<p>In contrast, the Wald interval gives poor results for small k, n.
For k = 0 or k = n, the interval always has zero length.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">binom_conf_interval</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="mi">5</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="s1">&#39;wald&#39;</span><span class="p">)</span>  
<span class="go">array([[0.02111437, 0.18091075],</span>
<span class="go">       [0.37888563, 0.61908925]])</span>
</pre></div>
</div>
<p>For confidence intervals approaching 1, the Wald interval for
0 &lt; k &lt; n can give intervals that extend outside [0, 1]:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">binom_conf_interval</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="mi">5</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="s1">&#39;wald&#39;</span><span class="p">,</span> <span class="n">confidence_level</span><span class="o">=</span><span class="mf">0.99</span><span class="p">)</span>  
<span class="go">array([[-0.26077835, -0.16433593],</span>
<span class="go">       [ 0.66077835,  0.96433593]])</span>
</pre></div>
</div>
</dd></dl>

</div>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><h3>Page Contents</h3>
<ul>
<li><a class="reference internal" href="#">binom_conf_interval</a></li>
</ul>


        </div>
      </div>
      <div class="clearer"></div>
    </div>
<footer class="footer">
  <p class="pull-right">
    <a href="../_sources/api/astropy.stats.binom_conf_interval.rst.txt"
       rel="nofollow">Page Source</a> &nbsp;
    <a href="#">Back to Top</a></p>
  <p>
    &copy; Copyright 2011–2022, The Astropy Developers.<br/>
    Created using <a href="http://www.sphinx-doc.org/en/stable/">Sphinx</a> 3.5.4. &nbsp;
    Last built 09 May 2022. <br/>
  </p>
</footer>
  </body>
</html>